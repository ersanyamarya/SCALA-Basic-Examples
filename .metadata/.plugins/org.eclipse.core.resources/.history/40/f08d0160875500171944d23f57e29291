import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.log4j._

object Activity {
  def parseLine(line: String) = {
    val fields = line.split(",")
    val customerID = fields(0)
    val amount = fields(2)
    (customerID, amount)
  }
  def main(args: Array[String]) {
    Logger.getLogger("org").setLevel(Level.ERROR)

    // Create a SparkContext using every core of the local machine
    val sc = new SparkContext("local[*]", "MaxTemperatures")

    // Read each line of input data
    val lines = sc.textFile("/home/arya/workspaces/workspace_scala/1800.csv")

  }
}