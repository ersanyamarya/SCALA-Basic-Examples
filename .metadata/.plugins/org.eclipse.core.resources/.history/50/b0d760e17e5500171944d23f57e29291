
import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.log4j._
object CountWords {

  def main(args: Array[String]) {
    Logger.getLogger("org").setLevel(Level.ERROR)
    val sc = new SparkContext("local[*]", "CountWords")
    val lines = sc.textFile("/home/arya/workspaces/workspace_scala/test.txt")
    val par = lines.map(line => line.split("\n"))
    val words = par.map(word => (word,1)).reduceByKey(_+_)
    println("Number of words in this file: " + words)
  }
}